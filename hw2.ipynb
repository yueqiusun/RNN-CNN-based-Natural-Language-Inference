{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sentence1\tsentence2\tlabel\r\n",
      "A young girl in a pink shirt sitting on a dock viewing a body of water .\tA young girl watching the sunset over the water .\tneutral\r\n",
      "A woman is smiling while the man next to her is focused on a blue object with a pattern on it .\tTwo people are next to each other .\tentailment\r\n",
      "Across the river , you can see a large building .\tThe large building is full of apartments and tenants\tneutral\r\n",
      "a man in white shorts and a black shirt is paragliding on the ocean\tA man is riding a jetski on the ocean .\tcontradiction\r\n",
      "Four black dogs run together on bright green grass .\tFour dogs are preparing to be launched into space .\tcontradiction\r\n",
      "A female laying on her stomach in the water outside with umbrellas .\tThere is a women outdoors\tentailment\r\n",
      "Children eat at a long table with black chairs .\tKids at a short table with red chairs .\tcontradiction\r\n",
      "A person rides a motorcycle quickly .\tThe man is racing his motorcycle in a race .\tneutral\r\n",
      "Woman riding a red bicycle down a city street , with a few people in the background .\tperson riding a bike\tentailment\r\n"
     ]
    }
   ],
   "source": [
    "!head ./hw2_data/snli_train.tsv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sentence1\tsentence2\tlabel\tgenre\r\n",
      "and now that was in fifty one that 's forty years ago that it was already a problem so it 's now uh\tIt was already a problem forty years ago but now it 's ten times worse !\tneutral\ttelephone\r\n",
      "Jon could smell baked bread on the air and his stomach rumbled .\tJon smelt food in the air and was hungry .\tneutral\tfiction\r\n",
      "it will be like Italian basketball with the uh with with the uh NBA\tThis type of Italian basketball is nothing like the NBA .\tcontradiction\ttelephone\r\n",
      "well i think that 's about uh that 's about covered it for me so i think i 'll say good-bye and we 'll\tSorry but we are not done just yet .\tcontradiction\ttelephone\r\n",
      "Good job tenure , that is -- because in yet another column , she sneers at Sara Davidson for working on Dr. Quinn , Medicine Woman . Why ca n't the silly creature get a perfect job like hers ?\tDr. Quinn , Medicine Woman , was worked on by Sara Davidson .\tentailment\tslate\r\n",
      "Second , the Senate request asked EPA to assume a 2002 start date in running the technology and policy scenarios .\tThe EPA started running the policy scenarios after 2002\tneutral\tgovernment\r\n",
      "have to see what uh April or May have to offer\tWe have to see how April and May will be .\tentailment\ttelephone\r\n",
      "Finally , boards have a clear responsibility to hold management accountable for results .\tManagement needs to be held accountable for results because all problems are the fault of management .\tneutral\tgovernment\r\n",
      "3 The Reorganization Act replaced this statutory codification of postal services with an administrative process in which the Governors of the Postal Service establish , and the Postal Rate Commission reviews proposed changes in , the terms and conditions of postal services , which are compiled as the Domestic Mail Classification Schedule ( or DMCS ) .\tPostal Service Governors are not authorized to review any previous Postal Service changes .\tneutral\tgovernment\r\n",
      "yeah he was pretty good staying on the sidelines with his clipboard but he was n't he was n't worth a damn in the game\tHe performed fantastically in the game .\tcontradiction\ttelephone\r\n",
      "On the central supporting pillar is a statue of John the Baptist ' beheaded not by Herod but by iconoclastic Huguenot vandals .\tThe statue of John the Baptist is the only one beheaded by the Huguenot vandals .\tneutral\ttravel\r\n",
      "Jon turned to Adrin , Vrenna , and San'doro .\tJon walked away without acknowledging the other three people .\tcontradiction\tfiction\r\n",
      "Slowly Tommy spoke .\tTommy did not talk quickly .\tentailment\tfiction\r\n",
      "Much of the money given away by the Slate 60 goes to finance new buildings at already wealthy universities .\tThe Slate 60 gives away a lot of money to finance new buildings at wealthy universities .\tentailment\tslate\r\n",
      "and you know how much you 're going to drive every week\tYour driving changes every week .\tcontradiction\ttelephone\r\n",
      "Even today there are few roads this really is one of the last true vestiges of wilderness in Jamaica .\tThe highway parts this area of extreme human developement .\tcontradiction\ttravel\r\n",
      "The 21 heads discovered in 1977 are now displayed in the Musee de Cluny .\tMusee de Cluny has the items recovered in 1977 .\tentailment\ttravel\r\n",
      "well not that much though\tYes , a whole lot of them .\tcontradiction\ttelephone\r\n",
      "Regulars have shown up yearly for decades .\tRegulars all abandoned it .\tcontradiction\ttravel\r\n"
     ]
    }
   ],
   "source": [
    "!head -20 ./hw2_data/mnli_train.tsv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n"
     ]
    }
   ],
   "source": [
    "# First lets improve libraries that we are going to be used in this lab session\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset\n",
    "from collections import Counter\n",
    "import pickle as pkl\n",
    "import random\n",
    "import pdb\n",
    "random.seed(134)\n",
    "\n",
    "from bagofwords import BagOfWords\n",
    "from hyperparameter import Hyperparameter as hp\n",
    "\n",
    "\n",
    "import re\n",
    " \n",
    "from train_f import *\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "print(device)\n",
    "\n",
    "PAD_IDX = 0\n",
    "UNK_IDX = 1\n",
    "BATCH_SIZE = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def build_all_tokens(inp1, inp2):\n",
    "    all_tokens = []\n",
    "    for sent in inp1:\n",
    "        for x in sent:\n",
    "            all_tokens.append(x)   \n",
    "    for sent in inp2:\n",
    "        for x in sent:\n",
    "            all_tokens.append(x)    \n",
    "    \n",
    "    return all_tokens\n",
    "    \n",
    "def read_data(filename, count = 9999999):\n",
    "    x1 = []\n",
    "    x2 = []\n",
    "    y = []\n",
    "    x1_w = []\n",
    "    x2_w = []\n",
    "    raw_data = []\n",
    "    filename =hp.prepath_data + filename\n",
    "    len_list = []\n",
    "    with open(filename, \"r\") as f:\n",
    "\n",
    "        line_num = 0\n",
    "        line = f.readline()\n",
    "        line = f.readline()\n",
    "        while line != None and line != \"\" and line_num<count:\n",
    "            line = line.lower()\n",
    "            arr = line.split('\\t')\n",
    "            #list of length of  sentences\n",
    "            x1.append(arr[0])\n",
    "            x2.append(arr[1])\n",
    "            y.append(hp.dummy2int[arr[2][:-1]])\n",
    "            line_num += 1\n",
    "            raw_data.append(line)\n",
    "            line = f.readline()\n",
    "        x1_w = [line.split() for line in x1]\n",
    "        x2_w = [line.split() for line in x2]\n",
    "        len_list = [len(line.split()) for line in x1]\n",
    "        len_list += [len(line.split()) for line in x2]\n",
    "        # take the 99 precentile of the length, let it be maximum sentence length\n",
    "        if count < 1000:\n",
    "            MAX_SENTENCE_LENGTH = sorted(len_list, reverse = True)[0]\n",
    "        else:\n",
    "            MAX_SENTENCE_LENGTH = sorted(len_list, reverse = True)[1000]\n",
    "        a = sorted(len_list, reverse = True)\n",
    "        \n",
    "        all_tokens = build_all_tokens(x1_w, x2_w)\n",
    "    return x1_w, x2_w, y, MAX_SENTENCE_LENGTH, all_tokens\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#count = 10000\n",
    "count = 9999999999\n",
    "train_x1, train_x2, train_y, MAX_SENTENCE_LENGTH, all_train_tokens  = read_data('snli_train.tsv', count = count)\n",
    "val_x1, val_x2, val_y, _, _ = read_data('snli_val.tsv', count = count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "\n",
    "max_vocab_size = 20000\n",
    "# save index 0 for unk and 1 for pad\n",
    "PAD_IDX = 0\n",
    "UNK_IDX = 1\n",
    "\n",
    "def build_vocab(all_tokens):\n",
    "    # Returns:\n",
    "    # id2token: list of tokens, where id2token[i] returns token that corresponds to token i\n",
    "    # token2id: dictionary where keys represent tokens and corresponding values represent indices\n",
    "    token_counter = Counter(all_tokens)\n",
    "    vocab, count = zip(*token_counter.most_common(max_vocab_size))\n",
    "    id2token = list(vocab)\n",
    "    token2id = dict(zip(vocab, range(2,2+len(vocab)))) \n",
    "    id2token = ['<pad>', '<unk>'] + id2token\n",
    "    token2id['<pad>'] = PAD_IDX \n",
    "    token2id['<unk>'] = UNK_IDX\n",
    "    return token2id, id2token\n",
    "\n",
    "token2id, id2token = build_vocab(all_train_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train dataset 1 size is 100000\n",
      "Train dataset 2 size is 100000\n",
      "Val dataset 1 size is 1000\n",
      "Val dataset 2 size is 1000\n"
     ]
    }
   ],
   "source": [
    "# convert token to id in the dataset\n",
    "def token2index_dataset(tokens_data):\n",
    "    indices_data = []\n",
    "    for tokens in tokens_data:\n",
    "        index_list = [token2id[token] if token in token2id else UNK_IDX for token in tokens]\n",
    "        indices_data.append(index_list)\n",
    "    return indices_data\n",
    "\n",
    "train_x1_indices = token2index_dataset(train_x1)\n",
    "train_x2_indices = token2index_dataset(train_x2)\n",
    "val_x1_indices = token2index_dataset(val_x1)\n",
    "val_x2_indices = token2index_dataset(val_x2)\n",
    "\n",
    "# double checking\n",
    "print (\"Train dataset 1 size is {}\".format(len(train_x1_indices)))\n",
    "print (\"Train dataset 2 size is {}\".format(len(train_x2_indices)))\n",
    "print (\"Val dataset 1 size is {}\".format(len(val_x1_indices)))\n",
    "print (\"Val dataset 2 size is {}\".format(len(val_x2_indices)))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ft_home = './'\n",
    "words_to_load = 50000\n",
    "emb_dim =  300\n",
    "\n",
    "with open(ft_home + 'wiki-news-300d-1M.vec') as f:\n",
    "    loaded_embeddings_ft = np.zeros((len(id2token), emb_dim))\n",
    "    words_ft = {}\n",
    "    idx2words_ft = {}\n",
    "    ordered_words_ft = []\n",
    "    for i, line in enumerate(f):\n",
    "        if i >= words_to_load: \n",
    "            break\n",
    "        s = line.split()\n",
    "        #if the word in vocabulary is in fasttext, we load the embedding for that word.\n",
    "        if s[0] in token2id:\n",
    "            idx = token2id[s[0]]\n",
    "            loaded_embeddings_ft[idx] = np.asarray(s[1:])\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11570\n"
     ]
    }
   ],
   "source": [
    "#if the word in vocabulary is not in fasttext(include unk and pad), we initialize a random vector.\n",
    "mask_emb = np.zeros(len(id2token))\n",
    "count = 0\n",
    "for i in range(len(id2token)):\n",
    "    if loaded_embeddings_ft[i][0] == 0:\n",
    "        mask_emb[i] = 1\n",
    "        loaded_embeddings_ft[i] = np.zeros((emb_dim, ))\n",
    "    else:\n",
    "        count += 1\n",
    "print(count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "class SNLIDataset(Dataset):\n",
    "    \"\"\"\n",
    "    Class that represents a train/validation/test dataset that's readable for PyTorch\n",
    "    Note that this class inherits torch.utils.data.Dataset\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, data_list1, data_list2,target_list):\n",
    "        \"\"\"\n",
    "        @param data_list: list of SNLI tokens \n",
    "        @param target_list: list of SNLI targets \n",
    "\n",
    "        \"\"\"\n",
    "        self.data_list1 = data_list1\n",
    "        self.data_list2 = data_list2\n",
    "        self.target_list = target_list\n",
    "        assert (len(self.data_list1) == len(self.target_list))\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data_list1)\n",
    "        \n",
    "    def __getitem__(self, key):\n",
    "        \"\"\"\n",
    "        Triggered when you call dataset[i]\n",
    "        \"\"\"\n",
    "        \n",
    "        token_idx1 = self.data_list1[key][:MAX_SENTENCE_LENGTH]\n",
    "        token_idx2 = self.data_list2[key][:MAX_SENTENCE_LENGTH]\n",
    "        label = self.target_list[key]\n",
    "        return [token_idx1, token_idx2, len(token_idx1), len(token_idx2),label]\n",
    "\n",
    "def SNLI_collate_func(batch):\n",
    "    \"\"\"\n",
    "    Customized function for DataLoader that dynamically pads the batch so that all \n",
    "    data have the same length\n",
    "    \"\"\"\n",
    "    data_list1 = []\n",
    "    data_list2 = []\n",
    "    label_list = []\n",
    "    length_list1 = []\n",
    "    length_list2 = []\n",
    "    #print(\"collate batch: \", batch[0][0])\n",
    "    #batch[0][0] = batch[0][0][:MAX_SENTENCE_LENGTH]\n",
    "    for datum in batch:\n",
    "        label_list.append(datum[4])\n",
    "        length_list1.append(datum[2])\n",
    "        length_list2.append(datum[3])\n",
    "    # padding\n",
    "    for datum in batch:\n",
    "        padded_vec1 = np.pad(np.array(datum[0]), \n",
    "                                pad_width=((0,MAX_SENTENCE_LENGTH-datum[2])), \n",
    "                                mode=\"constant\", constant_values=0)\n",
    "        padded_vec2 = np.pad(np.array(datum[1]), \n",
    "                                pad_width=((0,MAX_SENTENCE_LENGTH-datum[3])), \n",
    "                                mode=\"constant\", constant_values=0)\n",
    "        data_list1.append(padded_vec1)\n",
    "        data_list2.append(padded_vec2)\n",
    "    \n",
    "    #transform labels to one hot label to fit into cross-entropy loss\n",
    "    # define example\n",
    "    \n",
    "    \n",
    "    \n",
    "    return [torch.from_numpy(np.array(data_list1)), torch.from_numpy(np.array(data_list2)),\n",
    "            torch.LongTensor(length_list1), torch.LongTensor(length_list2),torch.LongTensor(label_list)]\n",
    "\n",
    "BATCH_SIZE = 100\n",
    "train_dataset = SNLIDataset(train_x1_indices, train_x2_indices,train_y)\n",
    "train_loader = torch.utils.data.DataLoader(dataset=train_dataset, \n",
    "                                           batch_size=BATCH_SIZE,\n",
    "                                           collate_fn=SNLI_collate_func,\n",
    "                                           shuffle=True)\n",
    "\n",
    "val_dataset = SNLIDataset(val_x1_indices, val_x2_indices, val_y)\n",
    "val_loader = torch.utils.data.DataLoader(dataset=val_dataset, \n",
    "                                           batch_size=BATCH_SIZE,\n",
    "                                           collate_fn=SNLI_collate_func,\n",
    "                                           shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def create_emb_layer(weights_matrix, non_trainable=False):\n",
    "    weights_matrix = torch.from_numpy(weights_matrix)\n",
    "    num_embeddings, embedding_dim = weights_matrix.size()\n",
    "    emb_layer = nn.Embedding(num_embeddings, embedding_dim)\n",
    "    emb_layer.load_state_dict({'weight': weights_matrix})\n",
    "#     if non_trainable:\n",
    "#         emb_layer.weight.requires_grad = False\n",
    "    \n",
    "\n",
    "    return emb_layer, num_embeddings, embedding_dim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#For the CNN, a 2-layer 1-D convolutional network with ReLU activations will suï¬ƒce. \n",
    "#We can perforzm a max-pool at the end to compress the hidden representation into a single vector.\n",
    "class CNN(nn.Module):\n",
    "    def __init__(self, weights_matrix, hidden_size, kernel_size, num_classes, mul, dp = -1):\n",
    "\n",
    "        super(CNN, self).__init__()\n",
    "\n",
    "        self.kernel_size, self.hidden_size = kernel_size, hidden_size\n",
    "        self.embedding, num_embeddings, embedding_dim = create_emb_layer(weights_matrix, True)\n",
    "        self.mul, self.dp = mul, dp\n",
    "        if self.mul != 1:\n",
    "            self.linear1_inputsize = self.hidden_size * 2\n",
    "        else:\n",
    "            self.linear1_inputsize = self.hidden_size\n",
    "        \n",
    "        self.conv = nn.Sequential(nn.Conv1d(embedding_dim, hidden_size, kernel_size=kernel_size, padding=0),\n",
    "                                   nn.ReLU(),\n",
    "                                  nn.Conv1d(hidden_size, hidden_size, kernel_size=kernel_size, padding=0),\n",
    "                                   nn.ReLU())\n",
    "        self.linear1 = nn.Sequential(nn.Linear(self.linear1_inputsize, self.linear1_inputsize), nn.ReLU())\n",
    "        if dp >= 0:\n",
    "            self.dropout = nn.Dropout(p=dp)\n",
    "\n",
    "        self.linear2 = nn.Linear(self.linear1_inputsize, num_classes)\n",
    "#             self.dropout = nn.dropout(dp)\n",
    "    def forward(self, x1, x2):\n",
    "        batch_size, seq_len = x1.size()\n",
    "\n",
    "        embed1 = self.embedding(x1).transpose(2,1) #batch_size * embedding dim * maximum_sentence_length \n",
    "        embed2 = self.embedding(x2).transpose(2,1)\n",
    "        out_conv1 = self.conv(embed1)  #batch_size * embedding dim * maximum_sentence_length - 2*kernel_size + 2\n",
    "        out_conv2 = self.conv(embed2) \n",
    "        out_pool1, _ = torch.max(out_conv1,dim = 2)\n",
    "        out_pool2, _ = torch.max(out_conv2,dim = 2)\n",
    "        if self.mul != 1:\n",
    "            out_pool = torch.cat((out_pool1, out_pool2), dim = 1)\n",
    "        else:\n",
    "            out_pool = torch.mul(out_pool1, out_pool2)\n",
    "            \n",
    "        linear_out1 = self.linear1(out_pool)\n",
    "        if self.dp >= 0:\n",
    "            out1 = self.dropout(linear_out1)\n",
    "        else:\n",
    "            out1 = linear_out1\n",
    "        logits = self.linear2(out1)\n",
    "        return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class RNN(nn.Module):\n",
    "    def __init__(self, weights_matrix, hidden_size, num_layers, num_classes, mul, dp = -1):\n",
    "        # RNN Accepts the following hyperparams:\n",
    "        # emb_size: Embedding Size\n",
    "        # hidden_size: Hidden Size of layer in RNN\n",
    "        # num_layers: number of layers in RNN\n",
    "        # num_classes: number of output classes\n",
    "        super(RNN, self).__init__()\n",
    "\n",
    "        self.num_layers, self.hidden_size = num_layers, hidden_size\n",
    "        self.embedding, num_embeddings, embedding_dim = create_emb_layer(weights_matrix, True)\n",
    "        self.mul, self.dp = mul, dp\n",
    "        if self.mul == 0:\n",
    "            self.linear1_inputsize = self.hidden_size * 4\n",
    "        else:\n",
    "            self.linear1_inputsize = self.hidden_size * 2\n",
    "\n",
    "        self.rnn = nn.GRU(embedding_dim, hidden_size, num_layers, batch_first=True, bidirectional = True) #dim1: batch dim2: sequence dim3: emb\n",
    "        self.linear1 = nn.Sequential(nn.Linear(self.linear1_inputsize, self.linear1_inputsize), nn.ReLU())\n",
    "        if self.dp >= 0:\n",
    "            self.dropout = nn.Dropout(p=dp)\n",
    "        self.linear2 = nn.Linear(self.linear1_inputsize, num_classes)\n",
    "    def init_hidden(self, batch_size):\n",
    "        # Function initializes the activation of recurrent neural net at timestep 0\n",
    "        # Needs to be in format (num_layers, batch_size, hidden_size)\n",
    "        hidden = torch.randn(self.num_layers * 2, batch_size, self.hidden_size).to(device)\n",
    "\n",
    "        return hidden\n",
    "        \n",
    "    def forward(self, x1,x2):\n",
    "        # reset hidden state\n",
    "\n",
    "        batch_size, seq_len = x1.size()\n",
    "        \n",
    "        self.hidden = self.init_hidden(batch_size)\n",
    "\n",
    "        \n",
    "        embed1 = self.embedding(x1)\n",
    "        embed2 = self.embedding(x2)\n",
    "\n",
    "        rnn_out1, self.hidden1 = self.rnn(embed1, self.hidden) #batch_size * maximum sentence length * hidden_size\n",
    "        rnn_out2, self.hidden2 = self.rnn(embed2, self.hidden)\n",
    "        rnn_out1_last = rnn_out1[:,-1,:]   #batch_size * hidden_size\n",
    "        rnn_out2_last = rnn_out2[:,-1,:]\n",
    "        if self.mul != 1:\n",
    "            out_pool = torch.cat((rnn_out1_last, rnn_out2_last),1)  #batch_size * hidden_size*2\n",
    "        else:\n",
    "            out_pool = torch.mul(rnn_out1_last, rnn_out2_last)\n",
    "            \n",
    "        linear_out1 = self.linear1(out_pool)\n",
    "        \n",
    "        if self.dp >= 0:\n",
    "            out1 = self.dropout(linear_out1)\n",
    "        else:\n",
    "            out1 = linear_out1\n",
    "        logits = self.linear2(out1)\n",
    "\n",
    "        return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Epoch: [1/2], Step: [101/1000], Training loss: 1.1186, Validation Acc: 32.9\n",
      " Epoch: [1/2], Step: [201/1000], Training loss: 1.1117, Validation Acc: 32.6\n",
      " Epoch: [1/2], Step: [301/1000], Training loss: 1.1076, Validation Acc: 33.8\n",
      " Epoch: [1/2], Step: [401/1000], Training loss: 1.0956, Validation Acc: 47.7\n",
      " Epoch: [1/2], Step: [501/1000], Training loss: 1.0787, Validation Acc: 53.6\n",
      " Epoch: [1/2], Step: [601/1000], Training loss: 1.0578, Validation Acc: 56.4\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-25-38bd627e7f88>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     58\u001b[0m         \u001b[0mlosses\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m         \u001b[0;31m# Backward and optimize\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 60\u001b[0;31m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     61\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m         \u001b[0;31m# validate every 100 iterations\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/lib/python3.5/site-packages/torch/tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[1;32m     91\u001b[0m                 \u001b[0mproducts\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0mDefaults\u001b[0m \u001b[0mto\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     92\u001b[0m         \"\"\"\n\u001b[0;32m---> 93\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     94\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/lib/python3.5/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[1;32m     87\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[1;32m     88\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 89\u001b[0;31m         allow_unreachable=True)  # allow_unreachable flag\n\u001b[0m\u001b[1;32m     90\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     91\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "kernel_size = 3\n",
    "learning_rate = 3e-3\n",
    "num_epochs = 2\n",
    "hidden_size = 200\n",
    "alr = 0\n",
    "wd = 1e-4\n",
    "def test_model(loader, model, criterion):\n",
    "    \"\"\"\n",
    "    Help function that tests the model's performance on a dataset\n",
    "    @param: loader - data loader for the dataset to test against\n",
    "    \"\"\"\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    model.eval()\n",
    "    losses = AverageMeter()\n",
    "    for data1,data2,lengths1,length2,labels in loader:\n",
    "        data1 = data1.to(device)\n",
    "        data2 = data2.to(device)\n",
    "        labels = labels.to(device)\n",
    "        outputs = model(data1, data2)\n",
    "        outputs_softmax = F.softmax(outputs, dim=1)\n",
    "        loss = criterion(outputs, labels)\n",
    "        losses.update(loss, data1.size(0))\n",
    "        predicted = outputs_softmax.max(1, keepdim=True)[1]\n",
    "\n",
    "        total += labels.size(0)\n",
    "\n",
    "        correct += predicted.eq(labels.view_as(predicted)).sum().item()\n",
    "\n",
    "    return (100 * correct / total), losses.avg\n",
    "\n",
    "\n",
    "model = RNN(weights_matrix=loaded_embeddings_ft, hidden_size=hidden_size, num_layers=1, num_classes=3, mul = 0, dp = 0.5).to(device)\n",
    "#model = CNN(weights_matrix=loaded_embeddings_ft, hidden_size=hidden_size, kernel_size=kernel_size, num_classes=3, mul = 1, dp = 0.3).to(device)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Criterion and Optimizer\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate, weight_decay = weight_decay)\n",
    "\n",
    "# Train the model\n",
    "total_step = len(train_loader)\n",
    "train_losses = []\n",
    "val_losses = []\n",
    "val_accs = []\n",
    "for epoch in range(1):\n",
    "    if alr:\n",
    "        adjust_learning_rate(lr, optimizer, epoch)\n",
    "    losses = AverageMeter()\n",
    "    for i, (x1, x2, lengths1, lengths2, labels) in enumerate(train_loader):\n",
    "        x1, x2, labels = x1.to(device), x2.to(device), labels.to(device)\n",
    "        model.train()\n",
    "        optimizer.zero_grad()\n",
    "        # Forward pass\n",
    "        outputs = model(x1, x2)\n",
    "        loss = criterion(outputs, labels)\n",
    "        losses.update(loss, x1.size(0))\n",
    "        # Backward and optimize\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        # validate every 100 iterations\n",
    "        if i > 0 and i % 100 == 0:\n",
    "            # validate\n",
    "            val_acc, val_loss = test_model(val_loader, model, criterion)\n",
    "            print(' Epoch: [{}/{}], Step: [{}/{}], Training loss: {loss.avg:.4f}, Validation Acc: {}'.format(\n",
    "                       epoch+1, num_epochs, i+1, len(train_loader), val_acc, loss = losses))\n",
    "    train_losses.append(losses.avg)\n",
    "    val_losses.append(val_loss)\n",
    "    val_accs.append(val_acc)\n",
    "\n",
    "print('Training loss: {loss.avg:.4f}, Validation loss: {}, Validation Acc: {}'.format(val_loss, val_acc, loss =losses))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "int() argument must be a string, a bytes-like object or a number, not 'NoneType'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-26-3f3b1d3c7325>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m: int() argument must be a string, a bytes-like object or a number, not 'NoneType'"
     ]
    }
   ],
   "source": [
    "int(None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.figure(figsize=(8, 5))\n",
    "plt.plot(train_losses)\n",
    "plt.xlabel('epoch')\n",
    "plt.ylabel('loss')\n",
    "#plt.savefig()\n",
    "plt.tight_layout()\n",
    "plt.title('Training Loss')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8, 5))\n",
    "plt.plot(val_losses)\n",
    "plt.xlabel('epoch')\n",
    "plt.ylabel('loss')\n",
    "#plt.savefig()\n",
    "plt.tight_layout()\n",
    "plt.title('validation Loss')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8, 5))\n",
    "plt.plot(val_accs)\n",
    "plt.xlabel('epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "#plt.savefig()\n",
    "plt.tight_layout()\n",
    "plt.title('Validation Accuracy')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def label2onehot_helper(x):\n",
    "    if x == 0:\n",
    "        return np.array([1,0,0])\n",
    "    elif x == 1:\n",
    "        return np.array([0,1,0])\n",
    "    elif x == 2:\n",
    "        return np.array([0,0,1])\n",
    "def label2onehot(labels):\n",
    "    labels = labels.numpy()\n",
    "    output = np.zeros((len(labels), 3))\n",
    "    for i, x in enumerate(labels):\n",
    "        output[i] = label2onehot_helper(x)\n",
    "   # output = np.squeeze(output,axis = 1)\n",
    "    return torch.LongTensor(output)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
